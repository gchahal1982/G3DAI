---
# PostgreSQL optimized configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: postgresql-config
  namespace: annotateai
data:
  postgresql.conf: |
    # Memory Configuration
    shared_buffers = 1GB
    effective_cache_size = 3GB
    maintenance_work_mem = 256MB
    checkpoint_completion_target = 0.9
    wal_buffers = 16MB
    default_statistics_target = 500
    random_page_cost = 1.1
    effective_io_concurrency = 200
    
    # Connection Settings
    max_connections = 200
    superuser_reserved_connections = 3
    
    # WAL Configuration
    wal_level = replica
    max_wal_senders = 3
    max_replication_slots = 3
    wal_keep_segments = 128
    checkpoint_segments = 64
    
    # Query Optimization
    work_mem = 16MB
    max_parallel_workers = 8
    max_parallel_workers_per_gather = 4
    
    # Logging
    log_statement = 'mod'
    log_min_duration_statement = 1000
    log_checkpoints = on
    log_connections = on
    log_disconnections = on
    log_lock_waits = on
    
    # AnnotateAI specific optimizations
    shared_preload_libraries = 'pg_stat_statements,auto_explain'
    pg_stat_statements.max = 10000
    pg_stat_statements.track = all
    auto_explain.log_min_duration = 5000
    auto_explain.log_analyze = on
    auto_explain.log_buffers = on
    auto_explain.log_timing = on
    auto_explain.log_verbose = on
    
  pg_hba.conf: |
    # TYPE  DATABASE        USER            ADDRESS                 METHOD
    local   all             all                                     trust
    host    all             all             127.0.0.1/32            trust
    host    all             all             ::1/128                 trust
    host    replication     all             127.0.0.1/32            trust
    host    replication     all             ::1/128                 trust
    host    all             all             0.0.0.0/0               md5
    host    replication     all             0.0.0.0/0               md5
    
  init-db.sql: |
    -- Create optimized indexes for AnnotateAI
    CREATE EXTENSION IF NOT EXISTS pg_stat_statements;
    CREATE EXTENSION IF NOT EXISTS auto_explain;
    CREATE EXTENSION IF NOT EXISTS pg_trgm;
    CREATE EXTENSION IF NOT EXISTS btree_gin;
    CREATE EXTENSION IF NOT EXISTS btree_gist;
    
    -- AnnotateAI database schema optimizations
    CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_annotations_user_id ON annotations(user_id);
    CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_annotations_project_id ON projects(project_id);
    CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_annotations_created_at ON annotations(created_at);
    CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_annotations_status ON annotations(status);
    CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_annotations_composite ON annotations(user_id, project_id, status, created_at);
    
    -- AI model performance indexes
    CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_ai_models_name ON ai_models(name);
    CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_ai_models_version ON ai_models(version);
    CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_ai_inference_logs_model_id ON ai_inference_logs(model_id);
    CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_ai_inference_logs_timestamp ON ai_inference_logs(timestamp);
    
    -- Collaboration indexes
    CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_collaboration_sessions_user_id ON collaboration_sessions(user_id);
    CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_collaboration_sessions_project_id ON collaboration_sessions(project_id);
    CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_collaboration_sessions_active ON collaboration_sessions(active);
    
    -- Full-text search indexes
    CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_annotations_content_gin ON annotations USING gin(content gin_trgm_ops);
    CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_projects_name_gin ON projects USING gin(name gin_trgm_ops);
    
    -- Partitioning for large tables
    CREATE TABLE IF NOT EXISTS annotation_logs_template (
        id SERIAL,
        annotation_id INTEGER NOT NULL,
        action VARCHAR(50) NOT NULL,
        timestamp TIMESTAMP NOT NULL,
        user_id INTEGER NOT NULL,
        details JSONB
    );
    
    -- Create partitioned table for annotation logs
    CREATE TABLE IF NOT EXISTS annotation_logs (
        LIKE annotation_logs_template INCLUDING ALL
    ) PARTITION BY RANGE (timestamp);
    
    -- Create monthly partitions
    CREATE TABLE IF NOT EXISTS annotation_logs_y2024m01 PARTITION OF annotation_logs
        FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');
    CREATE TABLE IF NOT EXISTS annotation_logs_y2024m02 PARTITION OF annotation_logs
        FOR VALUES FROM ('2024-02-01') TO ('2024-03-01');
    CREATE TABLE IF NOT EXISTS annotation_logs_y2024m03 PARTITION OF annotation_logs
        FOR VALUES FROM ('2024-03-01') TO ('2024-04-01');
    CREATE TABLE IF NOT EXISTS annotation_logs_y2024m04 PARTITION OF annotation_logs
        FOR VALUES FROM ('2024-04-01') TO ('2024-05-01');
    CREATE TABLE IF NOT EXISTS annotation_logs_y2024m05 PARTITION OF annotation_logs
        FOR VALUES FROM ('2024-05-01') TO ('2024-06-01');
    CREATE TABLE IF NOT EXISTS annotation_logs_y2024m06 PARTITION OF annotation_logs
        FOR VALUES FROM ('2024-06-01') TO ('2024-07-01');
    CREATE TABLE IF NOT EXISTS annotation_logs_y2024m07 PARTITION OF annotation_logs
        FOR VALUES FROM ('2024-07-01') TO ('2024-08-01');
    CREATE TABLE IF NOT EXISTS annotation_logs_y2024m08 PARTITION OF annotation_logs
        FOR VALUES FROM ('2024-08-01') TO ('2024-09-01');
    CREATE TABLE IF NOT EXISTS annotation_logs_y2024m09 PARTITION OF annotation_logs
        FOR VALUES FROM ('2024-09-01') TO ('2024-10-01');
    CREATE TABLE IF NOT EXISTS annotation_logs_y2024m10 PARTITION OF annotation_logs
        FOR VALUES FROM ('2024-10-01') TO ('2024-11-01');
    CREATE TABLE IF NOT EXISTS annotation_logs_y2024m11 PARTITION OF annotation_logs
        FOR VALUES FROM ('2024-11-01') TO ('2024-12-01');
    CREATE TABLE IF NOT EXISTS annotation_logs_y2024m12 PARTITION OF annotation_logs
        FOR VALUES FROM ('2024-12-01') TO ('2025-01-01');
    
    -- Create function to automatically create future partitions
    CREATE OR REPLACE FUNCTION create_monthly_partition(table_name text, start_date date)
    RETURNS void AS $$
    DECLARE
        partition_name text;
        end_date date;
    BEGIN
        partition_name := table_name || '_y' || to_char(start_date, 'YYYY') || 'm' || to_char(start_date, 'MM');
        end_date := start_date + interval '1 month';
        
        EXECUTE format('CREATE TABLE IF NOT EXISTS %I PARTITION OF %I FOR VALUES FROM (%L) TO (%L)',
                      partition_name, table_name, start_date, end_date);
    END;
    $$ LANGUAGE plpgsql;
    
    -- Materialized views for analytics
    CREATE MATERIALIZED VIEW IF NOT EXISTS annotation_stats_daily AS
    SELECT 
        date_trunc('day', created_at) as day,
        user_id,
        project_id,
        count(*) as annotation_count,
        avg(CASE WHEN status = 'completed' THEN 1 ELSE 0 END) as completion_rate
    FROM annotations
    GROUP BY date_trunc('day', created_at), user_id, project_id
    WITH DATA;
    
    CREATE UNIQUE INDEX IF NOT EXISTS idx_annotation_stats_daily_unique 
    ON annotation_stats_daily (day, user_id, project_id);
    
    CREATE MATERIALIZED VIEW IF NOT EXISTS ai_model_performance_daily AS
    SELECT 
        date_trunc('day', timestamp) as day,
        model_id,
        count(*) as inference_count,
        avg(duration) as avg_duration,
        percentile_cont(0.95) WITHIN GROUP (ORDER BY duration) as p95_duration,
        avg(CASE WHEN status = 'success' THEN 1 ELSE 0 END) as success_rate
    FROM ai_inference_logs
    GROUP BY date_trunc('day', timestamp), model_id
    WITH DATA;
    
    CREATE UNIQUE INDEX IF NOT EXISTS idx_ai_model_performance_daily_unique 
    ON ai_model_performance_daily (day, model_id);
---
# PgBouncer connection pooling
apiVersion: v1
kind: ConfigMap
metadata:
  name: pgbouncer-config
  namespace: annotateai
data:
  pgbouncer.ini: |
    [databases]
    annotateai = host=postgresql-primary port=5432 dbname=annotateai
    
    [pgbouncer]
    listen_addr = 0.0.0.0
    listen_port = 6432
    auth_type = md5
    auth_file = /etc/pgbouncer/userlist.txt
    
    # Pool configuration
    pool_mode = transaction
    max_client_conn = 1000
    default_pool_size = 100
    max_db_connections = 100
    reserve_pool_size = 10
    
    # Connection limits
    server_lifetime = 3600
    server_idle_timeout = 600
    client_idle_timeout = 0
    
    # Logging
    log_connections = 1
    log_disconnections = 1
    log_pooler_errors = 1
    
    # Admin
    admin_users = admin
    stats_users = admin
    
  userlist.txt: |
    "annotateai_user" "md5<password_hash>"
    "admin" "md5<admin_password_hash>"
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: pgbouncer
  namespace: annotateai
spec:
  replicas: 2
  selector:
    matchLabels:
      app: pgbouncer
  template:
    metadata:
      labels:
        app: pgbouncer
    spec:
      containers:
      - name: pgbouncer
        image: pgbouncer/pgbouncer:1.21.0
        ports:
        - containerPort: 6432
          name: pgbouncer
        - containerPort: 8080
          name: metrics
        volumeMounts:
        - name: config
          mountPath: /etc/pgbouncer
        env:
        - name: DATABASES_HOST
          value: "postgresql-primary"
        - name: DATABASES_PORT
          value: "5432"
        - name: DATABASES_USER
          value: "annotateai_user"
        - name: DATABASES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: postgresql-secret
              key: password
        resources:
          limits:
            cpu: 500m
            memory: 256Mi
          requests:
            cpu: 100m
            memory: 128Mi
        livenessProbe:
          tcpSocket:
            port: 6432
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          tcpSocket:
            port: 6432
          initialDelaySeconds: 10
          periodSeconds: 5
      volumes:
      - name: config
        configMap:
          name: pgbouncer-config
---
apiVersion: v1
kind: Service
metadata:
  name: pgbouncer-service
  namespace: annotateai
spec:
  selector:
    app: pgbouncer
  ports:
  - port: 6432
    targetPort: 6432
    name: pgbouncer
  - port: 8080
    targetPort: 8080
    name: metrics
---
# Redis optimization
apiVersion: v1
kind: ConfigMap
metadata:
  name: redis-config
  namespace: annotateai
data:
  redis.conf: |
    # Memory optimization
    maxmemory 2gb
    maxmemory-policy allkeys-lru
    
    # Performance tuning
    tcp-keepalive 300
    timeout 0
    tcp-backlog 511
    
    # Persistence
    save 900 1
    save 300 10
    save 60 10000
    
    # AnnotateAI specific configurations
    # Cache for annotations
    hash-max-ziplist-entries 512
    hash-max-ziplist-value 64
    
    # Session storage
    set-max-intset-entries 512
    
    # Real-time collaboration
    list-max-ziplist-size -2
    list-compress-depth 0
    
    # Pub/Sub for collaboration
    client-output-buffer-limit pubsub 32mb 8mb 60
    
    # Logging
    loglevel notice
    logfile /var/log/redis/redis.log
    
    # Security
    protected-mode yes
    bind 0.0.0.0
    port 6379
    
    # Modules for search and JSON
    # loadmodule /usr/lib/redis/modules/redisearch.so
    # loadmodule /usr/lib/redis/modules/rejson.so
---
# Database maintenance jobs
apiVersion: batch/v1
kind: CronJob
metadata:
  name: db-maintenance
  namespace: annotateai
spec:
  schedule: "0 2 * * *"  # Run at 2 AM daily
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: db-maintenance
            image: postgres:15
            command:
            - /bin/bash
            - -c
            - |
              # Connect to database
              export PGPASSWORD=$POSTGRES_PASSWORD
              
              # Vacuum and analyze
              echo "Running VACUUM ANALYZE..."
              psql -h $POSTGRES_HOST -U $POSTGRES_USER -d $POSTGRES_DB -c "VACUUM ANALYZE;"
              
              # Update statistics
              echo "Updating statistics..."
              psql -h $POSTGRES_HOST -U $POSTGRES_USER -d $POSTGRES_DB -c "ANALYZE;"
              
              # Refresh materialized views
              echo "Refreshing materialized views..."
              psql -h $POSTGRES_HOST -U $POSTGRES_USER -d $POSTGRES_DB -c "REFRESH MATERIALIZED VIEW CONCURRENTLY annotation_stats_daily;"
              psql -h $POSTGRES_HOST -U $POSTGRES_USER -d $POSTGRES_DB -c "REFRESH MATERIALIZED VIEW CONCURRENTLY ai_model_performance_daily;"
              
              # Clean up old partitions (older than 6 months)
              echo "Cleaning up old partitions..."
              psql -h $POSTGRES_HOST -U $POSTGRES_USER -d $POSTGRES_DB -c "
                DO \$\$
                DECLARE
                    partition_name text;
                BEGIN
                    FOR partition_name IN
                        SELECT schemaname||'.'||tablename 
                        FROM pg_tables 
                        WHERE tablename LIKE 'annotation_logs_y%' 
                        AND schemaname = 'public'
                    LOOP
                        IF substring(partition_name from '[0-9]{4}m[0-9]{2}') < to_char(now() - interval '6 months', 'YYYYmMM') THEN
                            EXECUTE 'DROP TABLE IF EXISTS ' || partition_name;
                        END IF;
                    END LOOP;
                END
                \$\$;
              "
              
              # Create next month's partition
              echo "Creating next month's partition..."
              psql -h $POSTGRES_HOST -U $POSTGRES_USER -d $POSTGRES_DB -c "
                SELECT create_monthly_partition('annotation_logs', date_trunc('month', now() + interval '1 month')::date);
              "
              
              echo "Database maintenance completed."
            env:
            - name: POSTGRES_HOST
              value: "postgresql-primary"
            - name: POSTGRES_USER
              value: "annotateai_user"
            - name: POSTGRES_DB
              value: "annotateai"
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: postgresql-secret
                  key: password
          restartPolicy: OnFailure
---
# Query performance monitoring
apiVersion: batch/v1
kind: CronJob
metadata:
  name: query-performance-monitor
  namespace: annotateai
spec:
  schedule: "*/15 * * * *"  # Run every 15 minutes
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: query-monitor
            image: postgres:15
            command:
            - /bin/bash
            - -c
            - |
              export PGPASSWORD=$POSTGRES_PASSWORD
              
              # Check for long-running queries
              echo "Checking for long-running queries..."
              psql -h $POSTGRES_HOST -U $POSTGRES_USER -d $POSTGRES_DB -c "
                SELECT 
                    pid,
                    now() - pg_stat_activity.query_start AS duration,
                    query,
                    state
                FROM pg_stat_activity
                WHERE (now() - pg_stat_activity.query_start) > interval '5 minutes'
                AND state = 'active'
                ORDER BY duration DESC;
              "
              
              # Check for blocked queries
              echo "Checking for blocked queries..."
              psql -h $POSTGRES_HOST -U $POSTGRES_USER -d $POSTGRES_DB -c "
                SELECT 
                    blocked_locks.pid AS blocked_pid,
                    blocked_activity.usename AS blocked_user,
                    blocking_locks.pid AS blocking_pid,
                    blocking_activity.usename AS blocking_user,
                    blocked_activity.query AS blocked_statement,
                    blocking_activity.query AS blocking_statement
                FROM pg_catalog.pg_locks blocked_locks
                JOIN pg_catalog.pg_stat_activity blocked_activity ON blocked_activity.pid = blocked_locks.pid
                JOIN pg_catalog.pg_locks blocking_locks ON blocking_locks.locktype = blocked_locks.locktype
                    AND blocking_locks.DATABASE IS NOT DISTINCT FROM blocked_locks.DATABASE
                    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation
                    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page
                    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple
                    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid
                    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid
                    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid
                    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid
                    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid
                    AND blocking_locks.pid != blocked_locks.pid
                JOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid
                WHERE NOT blocked_locks.GRANTED;
              "
              
              # Top slow queries
              echo "Top slow queries..."
              psql -h $POSTGRES_HOST -U $POSTGRES_USER -d $POSTGRES_DB -c "
                SELECT 
                    query,
                    calls,
                    total_time,
                    mean_time,
                    rows
                FROM pg_stat_statements
                WHERE calls > 10
                ORDER BY mean_time DESC
                LIMIT 10;
              "
            env:
            - name: POSTGRES_HOST
              value: "postgresql-primary"
            - name: POSTGRES_USER
              value: "annotateai_user"
            - name: POSTGRES_DB
              value: "annotateai"
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: postgresql-secret
                  key: password
          restartPolicy: OnFailure 